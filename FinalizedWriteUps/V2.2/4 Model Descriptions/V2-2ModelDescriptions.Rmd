---
csl: mathematical-biosciences-and-engineering.csl
output:
  pdf_document: 
    df_print: kable
    includes:
      in_header: Rmarkdown_preamble.tex
  word_document: 
geometry: margin=1.0in
fontsize: 12pt
subtitle: Version v2.2-Model Descriptions
bibliography: Bib_AccRefSheet.bib
---


<!------------------------------------------------------------------------------>
<!--  ####  KNITR Setup & Script Information   #### -->
<!------------------------------------------------------------------------------>

<!--  ####  KNITR Specs   #### -->
```{r setup, cache=TRUE, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo=FALSE, 
                      cache = TRUE, 
                      fig.align = "center",
                      fig.width = 5)
```


<!-- ####	 Set Working Directory	 ####   -->
```{r, echo=FALSE}
WD="/Users/lee/Documents/GitHub/MSproject_RBC/MSproject_RBC/FinalizedWriteUps/V2.2/4 Model Descriptions"
setwd(WD)
```
<!------------------------------------------------------------------------------>

<!------------------------------------------------------------------------------>
<!-- ####	Model Descriptions	 ####   -->

# Model Descriptions

## Motivating Example Notation 

- Section Goals
  - State what major section goals are.
  - Develop major notation that will common across all models
  
- Content:  
  - Here we descibe a modeling framework for each method implemented in this paper.
  - A generalized framework is presented for a broader spectrum of application
  - Details are provided on the specific process used for results in this paper in \textit{Appendix: Derivation of Applied Variables}.
  - Notation:
  - we will describe each model using the generalized predictor-response pairing:
  $$\left(X_{ij},Y_{ij} \right)  \quad \text{for} \ \ i=1,\ldots,N \quad j=1,\ldots,n_{i} $$
  - $i=1,\ldots,N$ represents the observation's \textit{subject of origination}
  - $j=1,\ldots,n_{i}$ represents the single-cell measure index taken within subject $i$


## Motivating Example Notation 

In the previous sections we described two predictor-response pairings over which the methods described in the sections that follow will be applied.  In an effort to provide both a workable, generalized framework, and a clear explanation of the process used to obtain results, an exhaustive explanation of the variable transformation process as applied to the motivating example data is outlined in \textit{Appendix: Derivation of Applied Variables}

In the following sections, we describe each model framework using the generalized predictor-response paring:
$$\left(X_{ij},Y_{ij} \right)  \quad \text{for} \ \ i=1,\ldots,N \quad j=1,\ldots,n_{i} $$
Where $i=1,\ldots,N$ represents the observation's \textit{subject of origination} (subject from which the single-cell measurement was taken), and $j=1,\ldots,n_{i}$ represents the single-cell measure index taken within subject $i$ (the repeated measure index within each subject).


### Linear Model (LM)

Using the notation we defined above, we write the first model as:

$$Y_{ij}=\beta_{0} + \beta_{1} X_{ij} + \epsilon_{ij}$$

We note that this model does not account for any structure in the observations, and instead provides estimates for population-averaged relationships:

* The estimated average (across all observations, across all subjects) value of $Y$ when $X=0$ (intercept)
* On average (across all observations, across all subjects), the rate of change in $Y$ per unit increase in $X$ (slope)

The error term in the model, represented by $\epsilon_{ij}$ is a normally distributed random variable with mean zero and variance $\sigma_{\epsilon}^{2}$, denoted $\epsilon_{ij} \sim N\left(0,\sigma_{\epsilon}^{2} \right)$

### Linear Model with Fixed-Effect Intercept (LM-FE)

Adding a subject-specific intercept term allows us to account for within-subject correlation by uniformly shifting the mean of the fitted values specific to a subject.  This model is written as:

$$Y_{ij} = \beta_{0} + \beta_{1i}(subject_{i})+\beta_{2} X_{ij} + \epsilon_{ij}$$

where we define the term: 
$$
\beta_{1i}\left(subject_{i} \right)=
\begin{cases}
\beta_{1i} & \mbox{if} \quad subject_{i}=i \quad \text{for} \quad i=2,\ldots,N\\
0 & \mbox{if} \quad subject_{i} \neq i\\
0 & \mbox{if} \quad i=1
\end{cases}
$$

This model adds $N-1$ estimated parameters $\hat{\beta}_{1i}$ which are the average deviation for each subject from the global estimated mean Linear Model (LM).


## Linear Mixed Effects Models

The next category of modeling approaches we describe is linear mixed effect models with random effects.  Specifically, we describe two distinct linear mixed effect models that account for subject-correlation in a different manner than the previously discussed linear regression models.  Linear mixed efffects models do not require the assumption of independent observations.  Correlation structures such as autoregressive, moving-average, or simply unrestricted (unstructured) can be used. Additionally, if we can assume that the model responses have a multivariate normal distribution, the model parameters can be easily estimated using maximum likelihood estimation techniques such as Restricted Maximum Likelihood estimation (REML) [@fitzmaurice2012applied].  


### Linear Mixed Effects Model with Random Intercept (LMM-RI)

A random intercept linear mixed effects model (LMM-RI) differs from a linear model with subject specific effects in the way that observational correlation is accounted for.  We have seen that such correlation has been accounted for in the LM-FE model with specific mean differences by subject.  In order for this method to be justified, it must be the case that observations within a subject are uniformly influenced by the nested nature of the sampling method.  This assumptions is not always reasonable, and a method that allows for responses within each subject to vary randomy according to which subject they belong to, would be more appropriate.  A linear mixed effects model with a random intercept controls for subject-level correlations through the use of subject-specific variances, and therefore accomplishes this desired trait.  The LMM-RI model is written as: 

$$Y_{ij} = \beta_{0} + \beta_{1} X_{ij} + b_{0i}\left(subject_{i}\right) + \epsilon_{ij}$$
where
$$b_{0i} \sim N\left(0, \sigma_{b}^{2} \right) \quad \epsilon_{ij} \sim N\left(0, \sigma_{\epsilon}^{2} \right)$$
$$\text{for} \quad i \in \left \{ 1,\ldots,N   \right \} \quad \text{and} \quad j \in \left \{ 1,\ldots,n_{i}   \right \}$$
we assume that $b_{0i}$ and $\epsilon_{ij}$ are independent, and both random-components are assumed to have a mean of zero. 


### Linear Mixed Effect Model with Random Slope (LMM-RS)

A random slope linear mixed effects model differs from each of the previously considered methods because it allows for distinct relationships for each subject between the variables of interest. A model with a subject-specific fixed effect slope term accounts for subject-level observational correlation with expected differences between the subject-specific, predictor-response relationships.  However, this method still assumes that observations within subject are uniformly influenced by due to the nested sampling method. Sometimes, a method that allows for responses to vary randomly across the predictor-response relationship according to which subject they belong to, would be more appropriate.  A linear mixed effects model with a random slope controls for subject-level correlations through the use of subject-specific variances in the relationships between predictor and response, and therefore accomplished this desired trait.  The LMM-RS model is written as: 

$$Y_{ij} = \beta_{0} + \beta_{1} X_{ij} + b_{0i}\left(subject_{i}\right) + \left [ b_{1i}\left(subject_{i} \right) X_{ij}   \right ] + \epsilon_{ij}$$

where

$$\mathbf{b} = 
\begin{bmatrix}
b_{0i} \\
b_{1i}
\end{bmatrix} \sim 
N \left(\mathbf{0}, \mathbf{G} \right)$$

$$G=\begin{bmatrix}
\sigma_{b_{0}}^2 & \sigma_{b_{01}} \\
\sigma_{b_{10}} & \sigma_{b_{1}}^{2}\\
\end{bmatrix}$$

$$\epsilon_{ij} \sim N\left(\mathbf{0}, \sigma_{\epsilon}^{2}\mathbf{I}_{n_{i}} \right) $$

## Generalized Estimating Equations (GEE)

The Generalized Estimating Equation (GEE) method focuses on estimating the fixed effect parameters specified within a model.  The method does not directly estimate variances and covariances, but instead approximates these values using a "working variance-covariance" structure. 

Procedurally GEE estimates are computed by finding numerical solutions for
an \textit{estimating equation} $U(\mathbf{\beta})=0$, where

\begin{equation}
U(\mathbf{\beta})=\sum_{i=1}^{N} \left \{\mathbf{D}_{i}^{T}\mathbf{V}_{i}^{-1}\left(\mathbf{y}_{i} - \mathbf{\mu}_{i}(\beta) \right)   \right \}
\end{equation}

where:
\begin{align*}
g \left(\mathbf{\mu}_{i} (\beta) \right) &=\mathbf{\eta}_{i} = E\left [\mathbf{Y}_{i} | X_{i} \right ]\\
&= X_{i}^{T} \mathbf{\beta}
\end{align*} 
outlines the dependence of the marginal expectation of the response on the covariates through the link function $g()$, and therefore:
\begin{align*}
\mathbf{\mu}_{i} (\beta)  &= g^{-1} \left(\mathbf{\eta}_{i}\right)  = g^{-1} \left(E\left [\mathbf{Y}_{i} | X_{i} \right ] \right) \\
&= g^{-1} \left(X_{i}^{T} \mathbf{\beta} \right) 
\end{align*}
We also have:
$$\mathbf{D}_{i}=
\begin{bmatrix}
\frac{\partial \mu_{i1}}{\beta_{1}} & \frac{\partial \mu_{i1}}{\beta_{2}} & \cdots & \frac{\partial \mu_{i1}}{\beta_{p}}\\
\frac{\partial \mu_{i2}}{\beta_{1}} & \frac{\partial \mu_{i2}}{\beta_{2}} & \cdots & \frac{\partial \mu_{i2}}{\beta_{p}}\\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial \mu_{in_{i}}}{\beta_{1}} & \frac{\partial \mu_{in_{i}}}{\beta_{2}} & \cdots & \frac{\partial \mu_{in_{i}}}{\beta_{p}}\\
\end{bmatrix}$$

is the first derivative matrix.

$\mathbf{V}_{i}$ is the working covariance matrix.  This matrix can be estimated from hyper parameters created in the process of numerically solving for the GEE estimates $\beta_{GEE}$ that solve $U\left(\beta\right)=0$. Please see Fitzmaurice, Laird, and Ware [@fitzmaurice2012applied] for more information.

The GEE algorithm uses the following general steps to converge at an estimate:

1. Generalized linear modeling methods employing maximum likelihood estimation are used to obtain intial estimates for $\mathbf{\beta}$
2. Estimates for $\mathbf{\beta}$ (from 1) used to compute hyper-parameters
3. New estimates for hyper-parameters and working covariance matrix ($\mathbf{V}_{i}$) used to obtain new estimates for $\mathbf{\beta}$ by solving (1)
4. Repeat Steps 2 & 3 until algorithm converges

The algorithm is robust to misspecification of the observational covariance structure.  So initially incorrect specifications of the working cavariance matrix still converge to the appropriate structure form with algorithmic iteration.   

The GEE algorithm is stable, in-part due to the fact that the method estimates population-average effects.  Each of the previous methods (model LM withstanding) have subject-specific interpretations, but the GEE algorithm provides marginal parameter estimates.  These values do not represent any specific subject, but rather averages over subjects.

According to Fitzmaurice, Laird, and Ware [@fitzmaurice2012applied], responses modeled with the GEE process need to be stationary, i.e:

$$E\left [ Y_{ij} | \mathbf{X}_{i} \right ]=E\left [ Y_{ij} | X_{i1}, \ldots, X_{in_{i}}\right ]=E\left [ Y_{ij} | X_{ij}\right ]$$
The scRNA-seq data is assumed to be independent within-subject, therefore we have:

$$E\left [Y_{ij} | X_{ij}\right ] = E\left [Y_{ij} | X_{ij'}\right ]$$
$$\forall j \in \left \{  1, \ldots, n_{i}\right \}  \quad j\neq j'$$
as needed.

The three-part specification of the GEE framework includes:

1. The link function and linear predictor
2. Variance function
3. A working covariance matrix 

All three items are chosen so that the resulting model estimates are comparable to preceeding estimates for intercept and slope. Therefore, we will use the identity link function:
$$g(x)=x$$
in conjunction with the linear predictor:
$$g(\mu_{i})=\eta_{i} = \beta_{0} + \beta_{1}X_{i}$$
which implies we assume the general observational-level modeling structure:
$$E\left [Y_{ij} \right ]=\mu_{ij}=\eta_{ij}= \beta_{0} + \beta_{1}X_{ij}$$
Additionally, we assume an identity variance function:
\begin{align*}
Var\left(Y_{ij} \right) &= \phi \nu\left(\mu_{ij}   \right)\\
&= \phi \mu_{ij}
\end{align*}
and use a working covariance matrix structure for repeated measures that correspond to the assumption of independence of observations within a subject.
$$\left [ Cov\left(Y_{ij}, Y_{ik}\right)\right ]_{jk}=
\begin{cases}
Var\left(Y_{ij}\right)  \quad &\mbox{if} \quad j=k \\
0 \quad &\mbox{if} \quad j \neq k \\
\end{cases}$$
$$for \quad j,k \in \left \{  1, \ldots, n_{i}   \right \}$$


## Parameter Interpretations 

- The GEE and LM modeling techniques are methods of obtaining estimates of population-averaged parameters.
  - parameter values interpreted as contributing to average response over all subjects (not representative of any single subject within the sample)

- Conversely, the LM-FE, LMM-RI and LMM-RS modeling techniques are methods of obtaining estimates of subject-specific parameters.
  - parameter values interpreted as contributing to the average response having controlled for a constant subject of origin (i.e. the parameter estimate attributable to a single subject within the sample) 
  
- Suppose that $\hat{\beta}_{population}$ represents an estimate obtained for the fixed effect slope as obtained by one of the previously describe \textit{population-averaged} modeling methods.  An interpretation of this paramter is:  **across all subjects, a one-unit increase in the predictor ($X_{ij}$) is associated with a $(\hat{\beta}_{population})$ unit change in the expected outcome ($Y_{ij}$)**

- Suppose that $\hat{\beta}_{subject}$ represents an estimate obtained for the fixed effect slope as obtained by one of the previously describe \textit{subject-specific} modeling methods.  An interpretation of this paramter is: **for a given subject (controlling for the subject of origin) a one-unit increase in the predictor ($X_{ij}$) is associated with a $(\hat{\beta}_{subject})$ unit change in the expected outcome ($Y_{ij}$).**



<!------------------------------------------------------------------------------>


# References

\bibliography{Bib_AccRefSheet}



